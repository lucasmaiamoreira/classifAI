{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto: Previsão de Fenômenos Climáticos\n",
    "\n",
    "##### URL para download dos dados\n",
    "https://www.ncei.noaa.gov/access/search/data-search/global-summary-of-the-month?bbox=70.088,-168.376,62.664,-143.987&pageNum=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Explique a motivação de uso da base escolhida. \n",
    "\n",
    "- Desenvolver um modelo de aprendizado de máquina para prever a ocorrência de fenômenos climáticos tempestades com base em variáveis climáticas e meteorológicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Descreva as variáveis presentes na base. Quais são as variáveis? Quais são os tipos de variáveis (discreta, categórica, contínua)? Quais são as médias e desvios padrões?\n",
    "\n",
    "1. Temperatura Média (TAVG)\n",
    "\n",
    "    - Tipo de Variável: Contínua\n",
    "\n",
    "    - Descrição: A temperatura média registrada durante um período específico.\n",
    "\n",
    "    - Média: 7.600328\n",
    "\n",
    "    - Desvio Padrão: 11.726153\n",
    "\n",
    "    - Mínimo: -17.130000\n",
    "\n",
    "    - Primeiro Quartil (Q1): -2.950000\n",
    "\n",
    "    - Mediana (Q2): 9.060000\n",
    "\n",
    "    - Terceiro Quartil (Q3): 18.825000\n",
    "\n",
    "    - Máximo: 25.620000\n",
    "\n",
    "2. Temperatura Máxima (TMAX)\n",
    "\n",
    "    - Tipo de Variável: Contínua\n",
    "\n",
    "    - Descrição: A temperatura máxima registrada durante um período específico.\n",
    "\n",
    "    - Média: 12.797264\n",
    "\n",
    "    - Desvio Padrão: 12.277433\n",
    "\n",
    "    - Mínimo: -12.560000\n",
    "\n",
    "    - Primeiro Quartil (Q1): 1.510000\n",
    "\n",
    "    - Mediana (Q2): 14.860000\n",
    "\n",
    "    - Terceiro Quartil (Q3): 24.455000\n",
    "\n",
    "    - Máximo: 32.530000\n",
    "\n",
    "3. Temperatura Mínima (TMIN)\n",
    "\n",
    "    - Tipo de Variável: Contínua\n",
    "\n",
    "    - Descrição: A temperatura mínima registrada durante um período específico.\n",
    "    \n",
    "    - Média: 2.402585\n",
    "\n",
    "    - Desvio Padrão: 11.218634\n",
    "\n",
    "    - Mínimo: -21.940000\n",
    "\n",
    "    - Primeiro Quartil (Q1): -7.265000\n",
    "\n",
    "    - Mediana (Q2): 3.370000\n",
    "\n",
    "    - Terceiro Quartil (Q3): 13.035000\n",
    "\n",
    "    - Máximo: 20.090000\n",
    "\n",
    "4. Precipitação (PRCP)\n",
    "\n",
    "    - Tipo de Variável: Contínua\n",
    "\n",
    "    - Descrição: A quantidade total de precipitação registrada durante um período específico.\n",
    "\n",
    "    - Média: 64.462137\n",
    "\n",
    "    - Desvio Padrão: 52.486282\n",
    "\n",
    "    - Mínimo: 0.000000\n",
    "\n",
    "    - Primeiro Quartil (Q1): 23.125000\n",
    "\n",
    "    - Mediana (Q2): 51.250000\n",
    "\n",
    "    - Terceiro Quartil (Q3): 93.425000\n",
    "\n",
    "    - Máximo: 305.800000\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Em relação à base escolhida:\n",
    "\n",
    "a. Você irá comparar alguns modelos para prever as classes. Descreva como a validação cruzada pode ser usada para comparar modelos de maneira justa. Descreva o procedimento e como a métrica final é calculada.\n",
    "\n",
    "A validação cruzada é uma técnica poderosa para avaliar a performance de modelos de aprendizado de máquina de maneira justa e robusta. Ela permite que você avalie como um modelo generaliza para dados não vistos, dividindo o conjunto de dados em um número específico de \"folds\" ou subconjuntos. O modelo é então treinado e testado várias vezes, cada vez em um conjunto diferente de folds, e os resultados são médios para obter uma estimativa mais precisa da performance do modelo.\n",
    "\n",
    "##### Os procedimentos da Validação Cruzada:\n",
    "\n",
    "1 - Divisão dos Dados: O conjunto de dados é dividido em k subconjuntos (ou \"folds\"). Normalmente, k é escolhido como 5 ou 10, mas pode ser qualquer número.\n",
    "\n",
    "2 - Treinamento e Teste: O modelo é treinado k vezes, cada vez usando k-1 dos folds como conjunto de treinamento e um fold diferente como conjunto de teste. Isso é feito para cada fold, de modo que cada fold seja usado uma vez como conjunto de teste.\n",
    "\n",
    "3 - Médias dos Resultados: As métricas de performance (como precisão, recall, F1-score, etc.) são calculadas para cada uma das k execuções. Em seguida, essas métricas são médias para obter uma estimativa mais precisa da performance do modelo.\n",
    "\n",
    "\n",
    "##### Métrica Final:\n",
    "\n",
    "A métrica final é calculada com base nas médias das métricas de performance obtidas nas k execuções da validação cruzada. A escolha da métrica final depende do objetivo do modelo.\n",
    "\n",
    " - Acurácia: A acurácia é uma métrica simples que indica a proporção de previsões corretas feitas pelo modelo. É útil para ter uma visão geral do desempenho do modelo.\n",
    "\n",
    " - Precisão: A proporção de previsões positivas corretas entre todas as previsões positivas. É útil quando a importância é dar prioridade às previsões positivas.\n",
    "\n",
    " - Recall: A proporção de previsões positivas corretas entre todas as previsões positivas reais. É útil quando a importância é detectar todas as instâncias positivas.\n",
    "\n",
    " - F1-Score: A média harmônica da precisão e do recall. É uma métrica equilibrada que considera tanto a precisão quanto o recall, sendo particularmente útil em situações onde é importante equilibrar essas duas métricas..\n",
    "\n",
    "b. A base se encontra com as classes balanceadas? Cite uma maneira de resolver no caso das classes estarem desbalanceadas.\n",
    "\n",
    "- Se a base de dados estiver desbalanceada, ou seja, se uma das classes (neste caso, a ocorrência de tempestades) tiver significativamente mais exemplos do que a outra, isso pode afetar negativamente o desempenho do modelo de aprendizado de máquina, fazendo com que ele tenha dificuldade em aprender a importância da classe minoritária. Existem várias estratégias para lidar com conjuntos de dados desbalanceados:\n",
    "\n",
    "1. Amostragem:\n",
    "    - Oversampling: Aumentar o número de exemplos da classe minoritária através da criação de cópias (ou \"amostragem duplicada\") ou da geração de novos exemplos (por exemplo, usando técnicas de aumento de dados).\n",
    "    - Undersampling: Reduzir o número de exemplos da classe majoritária para que o número de exemplos de ambas as classes seja igual.\n",
    "\n",
    "2. Ponderação de Classes:\n",
    "    - Ponderação de Classes: Ajustar os pesos das classes durante o treinamento do modelo para dar mais importância à classe minoritária. Isso pode ser feito através do parâmetro class_weight em muitos algoritmos de aprendizado de máquina no scikit-learn.\n",
    "\n",
    "3. Validação Cruzada:\n",
    "    - Validação Cruzada com Estratificação: Ao realizar a validação cruzada, garantir que cada fold contenha uma proporção representativa de ambas as classes. Isso pode ser feito usando a opção stratify no scikit-learn.\n",
    "\n",
    "4. Métricas de Avaliação\n",
    "    - Métricas Ajustadas: Além da acurácia, usar métricas que levem em conta o desbalanceamento das classes, como a área sob a curva ROC (AUC-ROC), precisão, recall e F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Qual a diferença entre uma regressão linear e a regressão logística?\n",
    "\n",
    "- Tipo de Variável Dependente: A principal diferença entre a regressão linear e a regressão logística é o tipo de variável dependente que elas preveem. A regressão linear preve valores contínuos, enquanto a regressão logística preve valores categóricos.\n",
    "\n",
    "- Função de Modelo: A regressão linear usa uma linha ou plano para modelar a relação entre as variáveis, enquanto a regressão logística usa uma função logística para modelar a probabilidade de uma variável categórica.\n",
    "\n",
    "- Interpretação dos Coeficientes: Os coeficientes da regressão linear indicam o efeito de uma unidade de mudança na variável independente na variável dependente, enquanto os coeficientes da regressão logística indicam o efeito de uma unidade de mudança na variável independente na mudança log-odds da probabilidade da variável categórica ser um dos possíveis valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Com a base escolhida:\n",
    "\n",
    "a. Descreva as etapas necessárias para criar um modelo de classificação eficiente.\n",
    "\n",
    "1. Entendimento do Problema:\n",
    "\n",
    "    - Definição do Problema: Compreender claramente o problema que você está tentando resolver. Isso inclui entender o contexto, os objetivos e as restrições.\n",
    "\n",
    "    - Definição dos Objetivos: Definir claramente o que você quer alcançar com o modelo. Isso pode incluir a previsão de uma variável categórica, a classificação de dados em grupos, entre outros.\n",
    "\n",
    "2. Preparação dos Dados:\n",
    "\n",
    "    - Coleta de Dados: Coletar os dados necessários para treinar e testar o modelo. Isso pode envolver a coleta de dados existentes ou a criação de um conjunto de dados através de simulações ou coleta de dados.\n",
    "\n",
    "    - Limpeza de Dados: Remover ou preencher valores ausentes, lidar com outliers e garantir que os dados estejam no formato correto.\n",
    "\n",
    "    - Divisão dos Dados: Dividir o conjunto de dados em conjuntos de treinamento e teste. Isso permite avaliar o desempenho do modelo em dados não vistos.\n",
    "\n",
    "    - Balanceamento de Classes: Se o conjunto de dados estiver desbalanceado, aplicar técnicas de balanceamento de classes, como amostragem ou ponderação de classes, para garantir que o modelo não seja tendencioso em relação a uma classe.\n",
    "\n",
    "3. Seleção do Modelo:\n",
    "\n",
    "    - Exploração de Modelos: Experimentar diferentes tipos de modelos de classificação para ver qual funciona melhor para o problema. Isso pode incluir modelos lineares, árvores de decisão, máquinas de vetores de suporte (SVM), redes neurais, entre outros.\n",
    "\n",
    "    - Ajuste de Hiperparâmetros: Ajustar os hiperparâmetros do modelo para melhorar seu desempenho. Isso pode ser feito através de validação cruzada ou outras técnicas de ajuste de hiperparâmetros.\n",
    "\n",
    "4. Treinamento do Modelo:\n",
    "\n",
    "    - Treinamento: Treinar o modelo selecionado usando o conjunto de treinamento. Isso envolve ajustar os parâmetros do modelo para minimizar um erro de previsão.\n",
    "\n",
    "    - Validação Cruzada: Usar validação cruzada para avaliar o desempenho do modelo em diferentes subconjuntos do conjunto de treinamento. Isso fornece uma estimativa mais robusta do desempenho do modelo.\n",
    "\n",
    "5. Avaliação do Modelo:\n",
    "\n",
    "    - Teste do Modelo: Testar o modelo no conjunto de teste para avaliar seu desempenho em dados não vistos.\n",
    "\n",
    "    - Análise de Métricas: Analisar métricas de desempenho como acurácia, precisão, recall, F1-score e área sob a curva ROC (AUC-ROC) para avaliar o desempenho do modelo.\n",
    "\n",
    "    - Interpretação dos Resultados: Interpretar os resultados do modelo e entender o que eles significam no contexto do problema.\n",
    "\n",
    "6. Ajuste e Validação:\n",
    "\n",
    "    - Ajuste Final: Com base na avaliação, fazer ajustes finais no modelo para melhorar seu desempenho.\n",
    "\n",
    "    - Validação Final: Validar o modelo final com um novo conjunto de dados para garantir que ele generalize bem para novos dados.\n",
    "\n",
    "7. Implementação e Monitoramento:\n",
    "\n",
    "    - Implementação: Implementar o modelo em um ambiente de produção ou em um sistema de previsão.\n",
    "\n",
    "    - Monitoramento: Monitorar o desempenho do modelo em produção e fazer ajustes conforme necessário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Treine um modelo de regressão logística para realizar a classificação. Qual a acurácia, a precisão, a recall e o f1-score do modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.stats import uniform, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os arquivos CSV\n",
    "def carregar_dados():\n",
    "    dfs = []\n",
    "    for i in range(1, 10):\n",
    "        df = pd.read_csv(f'data/USC00{i}.csv')\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Selecionando colunas do df e preenchendo valores ausentes\n",
    "def preparar_dados(dados):\n",
    "    dados_selecionados = dados[['TAVG', 'TMAX', 'TMIN', 'PRCP']]\n",
    "    return dados_selecionados.fillna(dados_selecionados.mean())\n",
    "\n",
    "# Criando uma variável indicadora binária\n",
    "def criar_variavel_alvo(dados):\n",
    "    return dados['PRCP'].apply(lambda x: 1 if x > 25 else 0)\n",
    "\n",
    "# Dividindo os dados em conjunto de treinamento e teste\n",
    "def dividir_dados(X, y):\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Realizando subamostragem (undersampling)\n",
    "def realizar_subamostragem(X, y):\n",
    "    undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "    return undersampler.fit_resample(X, y)\n",
    "\n",
    "# Realizando sobreamostragem (oversampling)\n",
    "def realizar_sobreamostragem(X, y):\n",
    "    oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "    return oversampler.fit_resample(X, y)\n",
    "\n",
    "# Avaliando o desempenho do modelo\n",
    "def avaliar_modelo(modelo, X_test, y_test):\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    acuracia = accuracy_score(y_test, y_pred)\n",
    "    precisao = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('')\n",
    "    print(\"Acurácia:\", acuracia)\n",
    "    print(\"Precisão:\", precisao)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-Score:\", f1)\n",
    "    print('')\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print('')\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando e preparando os dados\n",
    "dados = carregar_dados()\n",
    "X = preparar_dados(dados)\n",
    "y = criar_variavel_alvo(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanceamento antes da subamostragem:\n",
      "PRCP\n",
      "1    1985\n",
      "0    1417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = dividir_dados(X, y)\n",
    "\n",
    "# Verificando balanceamento antes da subamostragem e sobreamostragem\n",
    "print(\"Balanceamento antes da subamostragem:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanceamento após a subamostragem:\n",
      "PRCP\n",
      "0    1417\n",
      "1    1417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Realizando subamostragem\n",
    "X_under, y_under = realizar_subamostragem(X_train, y_train)\n",
    "\n",
    "# Verificando balanceamento após a subamostragem\n",
    "print(\"\\nBalanceamento após a subamostragem:\")\n",
    "print(pd.Series(y_under).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanceamento após a sobreamostragem:\n",
      "PRCP\n",
      "0    1985\n",
      "1    1985\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Realizando sobreamostragem\n",
    "X_over, y_over = realizar_sobreamostragem(X_train, y_train)\n",
    "\n",
    "# Verificando balanceamento após a sobreamostragem\n",
    "print(\"\\nBalanceamento após a sobreamostragem:\")\n",
    "print(pd.Series(y_over).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando modelo de Regressão Logística...\n",
      "Avaliação do modelo de Regressão Logística:\n",
      "\n",
      "Acurácia: 0.8834019204389575\n",
      "Precisão: 0.9122182680901542\n",
      "Recall: 0.8890173410404625\n",
      "F1-Score: 0.9004683840749415\n",
      "\n",
      "Relatório de Classificação:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       593\n",
      "           1       0.91      0.89      0.90       865\n",
      "\n",
      "    accuracy                           0.88      1458\n",
      "   macro avg       0.88      0.88      0.88      1458\n",
      "weighted avg       0.88      0.88      0.88      1458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando pipeline do modelo LogisticRegression\n",
    "pipeline_regressao_logistica = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Treinando modelo de Regressão Logística\n",
    "print(\"\\nTreinando modelo de Regressão Logística...\")\n",
    "pipeline_regressao_logistica.fit(X_train, y_train)\n",
    "print(\"Avaliação do modelo de Regressão Logística:\")\n",
    "avaliar_modelo(pipeline_regressao_logistica, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando modelo de Árvore de Decisão...\n",
      "Avaliação do modelo de Árvore de Decisão sem GridSearchCV:\n",
      "\n",
      "Acurácia: 0.9993141289437586\n",
      "Precisão: 1.0\n",
      "Recall: 0.9988439306358381\n",
      "F1-Score: 0.9994216310005783\n",
      "\n",
      "Relatório de Classificação:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       593\n",
      "           1       1.00      1.00      1.00       865\n",
      "\n",
      "    accuracy                           1.00      1458\n",
      "   macro avg       1.00      1.00      1.00      1458\n",
      "weighted avg       1.00      1.00      1.00      1458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando pipeline do modelo DecisionTreeClassifier\n",
    "pipeline_arvore_decisao = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Treinando modelo de Árvore de Decisão\n",
    "print(\"\\nTreinando modelo de Árvore de Decisão...\")\n",
    "pipeline_arvore_decisao.fit(X_train, y_train)\n",
    "print(\"Avaliação do modelo de Árvore de Decisão sem GridSearchCV:\")\n",
    "avaliar_modelo(pipeline_arvore_decisao, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Parâmetros para a Árvore de Decisão com GridSearchCV: {'classifier__criterion': 'entropy', 'classifier__max_depth': 3}\n",
      "Avaliação do melhor modelo da Árvore de Decisão com GridSearchCV:\n",
      "\n",
      "Acurácia: 1.0\n",
      "Precisão: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n",
      "\n",
      "Relatório de Classificação:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       593\n",
      "           1       1.00      1.00      1.00       865\n",
      "\n",
      "    accuracy                           1.00      1458\n",
      "   macro avg       1.00      1.00      1.00      1458\n",
      "weighted avg       1.00      1.00      1.00      1458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definindo os parâmetros para a busca exaustiva\n",
    "parametros_arvore_decisao = {\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': range(1, 11)\n",
    "}\n",
    "\n",
    "# Criando o pipeline da Árvore de Decisão com GridSearchCV\n",
    "pipeline_arvore_decisao = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Inicializando o GridSearchCV\n",
    "grid_search_arvore_decisao = GridSearchCV(\n",
    "    estimator=pipeline_arvore_decisao,\n",
    "    param_grid=parametros_arvore_decisao,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinando o modelo com GridSearchCV\n",
    "grid_search_arvore_decisao.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o melhor modelo da Árvore de Decisão\n",
    "melhor_modelo_arvore_decisao = grid_search_arvore_decisao.best_estimator_\n",
    "print(\"Melhores Parâmetros para a Árvore de Decisão com GridSearchCV:\", grid_search_arvore_decisao.best_params_)\n",
    "print(\"Avaliação do melhor modelo da Árvore de Decisão com GridSearchCV:\")\n",
    "avaliar_modelo(melhor_modelo_arvore_decisao, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando modelo de SVM...\n",
      "Avaliação do modelo de SVM:\n",
      "\n",
      "Acurácia: 0.9163237311385459\n",
      "Precisão: 0.9226393629124005\n",
      "Recall: 0.9375722543352601\n",
      "F1-Score: 0.930045871559633\n",
      "\n",
      "Relatório de Classificação:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       593\n",
      "           1       0.92      0.94      0.93       865\n",
      "\n",
      "    accuracy                           0.92      1458\n",
      "   macro avg       0.91      0.91      0.91      1458\n",
      "weighted avg       0.92      0.92      0.92      1458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criando o pipeline do modelo SVM\n",
    "pipeline_svm = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Treinando modelo de SVM\n",
    "print(\"\\nTreinando modelo de SVM...\")\n",
    "pipeline_svm.fit(X_train, y_train)\n",
    "print(\"Avaliação do modelo de SVM:\")\n",
    "avaliar_modelo(pipeline_svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Parâmetros para SVM com RandomizedSearchCV: {'classifier__C': 6.1111501174320875, 'classifier__kernel': 'rbf'}\n",
      "Avaliação do melhor modelo SVM:\n",
      "\n",
      "Acurácia: 0.9279835390946503\n",
      "Precisão: 0.9250559284116331\n",
      "Recall: 0.9560693641618497\n",
      "F1-Score: 0.9403069926094372\n",
      "\n",
      "Relatório de Classificação:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       593\n",
      "           1       0.93      0.96      0.94       865\n",
      "\n",
      "    accuracy                           0.93      1458\n",
      "   macro avg       0.93      0.92      0.92      1458\n",
      "weighted avg       0.93      0.93      0.93      1458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definindo os parâmetros para a busca aleatória\n",
    "parametros_svm = {\n",
    "    'classifier__C': uniform(0.1, 10),\n",
    "    'classifier__kernel': ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "# Criando o pipeline do SVM com RandomizedSearchCV\n",
    "pipeline_svm_random = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Inicializando o RandomizedSearchCV\n",
    "randomized_search_svm = RandomizedSearchCV(\n",
    "    estimator=pipeline_svm_random,\n",
    "    param_distributions=parametros_svm,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    n_iter=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinando o modelo com RandomizedSearchCV\n",
    "randomized_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando o melhor modelo SVM\n",
    "melhor_modelo_svm = randomized_search_svm.best_estimator_\n",
    "print(\"Melhores Parâmetros para SVM com RandomizedSearchCV:\", randomized_search_svm.best_params_)\n",
    "print(\"Avaliação do melhor modelo SVM:\")\n",
    "avaliar_modelo(melhor_modelo_svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Em relação à questão anterior, qual o modelo deveria ser escolhido para uma eventual operação. Responda essa questão mostrando a comparação de todos os modelos e justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para escolher o melhor modelo para uma eventual operação, vamos comparar os resultados dos modelos de Regressão Logística, Árvore de Decisão e SVM (com e sem GridSearchCV) com base em suas métricas de desempenho, incluindo acurácia, precisão, recall e F1-score.\n",
    "\n",
    "1. Regressão Logística:\n",
    "\n",
    "    - Acurácia: 0.8834\n",
    "    - Precisão: 0.9122\n",
    "    - Recall: 0.8890\n",
    "    - F1-Score: 0.9005\n",
    "\n",
    "2. Árvore de Decisão:\n",
    "\n",
    "    - Sem GridSearchCV:\n",
    "\n",
    "        - Acurácia: 0.9993\n",
    "        - Precisão: 1.0\n",
    "        - Recall: 0.9988\n",
    "        - F1-Score: 0.9994\n",
    "\n",
    "    - Com GridSearchCV:\n",
    "\n",
    "        - Acurácia: 1.0\n",
    "        - Precisão: 1.0\n",
    "        - Recall: 1.0\n",
    "        - F1-Score: 1.0\n",
    "\n",
    "3. SVM:\n",
    "\n",
    "    - Sem RandomizedSearchCV:\n",
    "\n",
    "        - Acurácia: 0.9163\n",
    "        - Precisão: 0.9226\n",
    "        - Recall: 0.9376\n",
    "        - F1-Score: 0.9300\n",
    "        \n",
    "    - Com RandomizedSearchCV:\n",
    "\n",
    "        - Acurácia: 0.9280\n",
    "        - Precisão: 0.9251\n",
    "        - Recall: 0.9561\n",
    "        - F1-Score: 0.9403\n",
    "\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "- Árvore de Decisão com GridSearchCV é o modelo que alcançou a perfeição nas métricas de avaliação (precisão, recall e F1-score) para ambas as classes, o que indica um desempenho excelente e sem falhas. Assim, considerando que atinge o melhor desempenho possível, seria a escolha preferencial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
